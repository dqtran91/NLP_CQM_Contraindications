{"cells":[{"cell_type":"code","source":["'''set the environment'''\n#import needed packages\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nimport fnmatch\n\n#data path\npath = \"\"\n\n\n#create and set database\n# spark.sql(f\"DROP DATABASE IF EXISTS {database} CASCADE\")\n# spark.sql(f\"CREATE DATABASE {database}\")\nspark.sql(f\"USE {database}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4e07be0-bad6-4b13-b776-d19158c87f44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25213685-cdd9-4f09-b168-43e7a3f78f7f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport itertools\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.corpus import stopwords\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\n#import classifiers from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n#import different metrics to evaluate the classifiers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\nfrom sklearn import metrics\n\n#matplotlib imports are used to plot confusion matrices for the classifiers\nimport matplotlib as mpl \nimport matplotlib.cm as cm \nimport matplotlib.pyplot as plt "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f73fba0-b404-4899-9a98-7113db784f82"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.table('textTable').toPandas()\nprint('textTable shape:', df.shape)\ndf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1004605d-f2dd-4a8d-8627-5d5bcaab77e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Let us take the top 3 categories and leave out the rest.\nshortlist = [1, 0]\nclasses = ['no contraindication', 'contraindication']\ndf_subset = df[df['label'].isin(shortlist)]\ndf_subset.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73b5e1a5-8f1a-4a10-b16f-d82b6eabb3f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#strip_handles removes personal information such as twitter handles, which don't\n#contribute to emotion in the tweet. preserve_case=False converts everything to lowercase.\ntweeter = TweetTokenizer(strip_handles=True,preserve_case=False)\nmystopwords = set(stopwords.words(\"english\"))\n\n#Function to tokenize tweets, remove stopwords and numbers. \n#Keeping punctuations and emoticon symbols could be relevant for this task!\ndef preprocess_corpus(texts):\n    def remove_stops_digits(tokens):\n        #Nested function that removes stopwords and digits from a list of tokens\n        return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n    #This return statement below uses the above function to process twitter tokenizer output further. \n    return [remove_stops_digits(tweeter.tokenize(content)) for content in texts]\n\n#df_subset contains only the three categories we chose. \nmydata = preprocess_corpus(df_subset['text'])\nmycats = df_subset['label']\nprint(len(mydata), len(mycats))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19b3c843-74b5-4cfc-831b-e204e2e8a0e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Split data into train and test, following the usual process\ntrain_data, test_data, train_cats, test_cats = train_test_split(mydata,mycats,random_state=1234)\n\n#prepare training data in doc2vec format:\ntrain_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(train_data)]\n#Train a doc2vec model to learn tweet representations. Use only training data!!\nmodel = Doc2Vec(vector_size=50, alpha=0.025, min_count=5, dm =1, epochs=100)\nmodel.build_vocab(train_doc2vec)\nmodel.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"d2v.model\")\nprint(\"Model Saved\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0da4e46-698e-4254-bbfa-7e996721ce22"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Infer the feature representation for training and test data using the trained model\nmodel= Doc2Vec.load(\"d2v.model\")\n#infer in multiple steps to get a stable representation. \ntrain_vectors =  [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in train_data]\ntest_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in test_data]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e39f31e6-744b-4457-ad55-754a35ff976c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#Evaluate the classifier using various measures\n\n# Function to plot confusion matrix. \n# Ref:http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label',fontsize=15)\n    plt.xlabel('Predicted label',fontsize=15)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8cdba36-519c-4db5-9d90-16c7809d4a87"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#logistic regression\nlrClass = LogisticRegression(class_weight=\"balanced\") #because classes are not balanced. \nlrClass.fit(train_vectors, train_cats)\n\npreds = lrClass.predict(test_vectors)\n\n# print classification report and accuracy:\nprint(classification_report(test_cats, preds))\nprint(\"Accuracy: \", accuracy_score(test_cats, preds))\n    \n# print the confusion matrix\ncnf_matrix = confusion_matrix(test_cats, preds)\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=classes, #normalize=True,\n                      title='Confusion matrix with all features')\n\n# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n#Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\npred_prob = lrClass.predict_proba(test_vectors)[:, 1]\nprint(\"ROC_AOC_Score: \", roc_auc_score(test_cats, pred_prob))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7acd59f-d1ae-4d91-86b5-207972ad350e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#naives bayes\nnbClass = GaussianNB()\nnbClass.fit(train_vectors, train_cats)\n\npreds = nbClass.predict(test_vectors)\n\n# print classification report and accuracy:\nprint(classification_report(test_cats, preds))\nprint(\"Accuracy: \", accuracy_score(test_cats, preds))\n    \n# print the confusion matrix\ncnf_matrix = confusion_matrix(test_cats, preds)\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=classes, #normalize=True,\n                      title='Confusion matrix with all features')\n\n# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n#Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\npred_prob = nbClass.predict_proba(test_vectors)[:, 1]\nprint(\"ROC_AOC_Score: \", roc_auc_score(test_cats, pred_prob))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5abd6335-b761-4da9-aeb5-130cd914875d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#support vector machine\nsvcClass = SVC(class_weight='balanced', probability=True)\nsvcClass.fit(train_vectors, train_cats)\n\npreds = svcClass.predict(test_vectors)\n\n# print classification report and accuracy:\nprint(classification_report(test_cats, preds))\nprint(\"Accuracy: \", accuracy_score(test_cats, preds))\n\n    \n# print the confusion matrix\ncnf_matrix = confusion_matrix(test_cats, preds)\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=classes, #normalize=True,\n                      title='Confusion matrix with all features')\n\n# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n#Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\npred_prob = svcClass.predict_proba(test_vectors)[:, 1]\nprint(\"ROC_AOC_Score: \", roc_auc_score(test_cats, pred_prob))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d051e02e-d27e-4c9c-85f2-22dd6b5f0761"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# print('the type of preds:', type(preds))\n\n# value = 1\n# correct_count = 0\n# incorrect_count = 0\n# for i in range(len(preds)):\n#   if preds[i] == value:\n#     print(f\"index:{i}, pred:{preds[i]}, true:{test_cats.iloc[i]}\")\n#     if preds[i] == test_cats.iloc[i]:\n#        correct_count = correct_count + 1 \n#     if preds[i] != test_cats.iloc[i]:\n#        incorrect_count = incorrect_count + 1 \n\n# print(f\"number of predicted {value}:{len(preds[preds == value])}\")\n# print(f\"number of correct {value}:{correct_count}\")\n# print(f\"number of incorrect {value}:{incorrect_count}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdafee3c-4170-4b79-9991-eafd372091f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Data Analysis","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2128806262638408}},"nbformat":4,"nbformat_minor":0}
